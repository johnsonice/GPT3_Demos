{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146ec016",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd01a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0,'../../libs')\n",
    "from utils import load_json\n",
    "\n",
    "### Load all API keys \n",
    "openai_key = load_json('/home/chengyu.huang/project/Fund_projects/openai_key.json') \n",
    "os.environ['OPENAI_API_KEY'] = openai_key['ChatGPT']['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6bc6f0",
   "metadata": {},
   "source": [
    "### initiate a llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db5c39ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengyu.huang/anaconda3/envs/sbert/lib/python3.8/site-packages/langchain/llms/openai.py:171: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/chengyu.huang/anaconda3/envs/sbert/lib/python3.8/site-packages/langchain/llms/openai.py:739: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI(\n",
    "    openai_api_key=os.environ['OPENAI_API_KEY'],  # platform.openai.com\n",
    "    temperature=0,\n",
    "    model_name=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74119c6c",
   "metadata": {},
   "source": [
    "#### Initialize a calculator tool using LLMMathChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa26d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMMathChain\n",
    "from langchain.agents import Tool\n",
    "\n",
    "llm_math = LLMMathChain.from_llm(llm=llm)\n",
    "\n",
    "# initialize the math tool\n",
    "math_tool = Tool(\n",
    "    name='Calculator',\n",
    "    func=llm_math.run,\n",
    "    description='Useful for when you need to answer questions about math.'\n",
    ")\n",
    "# when giving tools to LLM, we must pass as list of tools\n",
    "tools = [math_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa88b605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53e56e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a39cddb",
   "metadata": {},
   "source": [
    "#### intiate a zero shoot react agent to choose whcih tool to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9388cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "\tagent=\"zero-shot-react-description\",   ## for now, it doesn't have memory, only use description to do the filtering \n",
    "\ttools=tools,\n",
    "\tllm=llm,\n",
    "\tverbose=True,        ## set it to false, we can get output directly \n",
    "\tmax_iterations=3     ## limit it to max loop in case it get stucked \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e367658e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to use the calculator to solve this problem.\n",
      "Action: Calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 139.94261298333066\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## give it a simple try \n",
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b4ec1e",
   "metadata": {},
   "source": [
    "- a slightly more complicated problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6458a85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mWe need to convert the apple boxes to the number of apples they contain.\n",
      "Action: Calculator\n",
      "Action Input: 2.5 x 8\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 20.0\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5904a56c90a266cbb216338fc2cf6088 in your message.).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mNow we add the number of apples Giorgio brought to the number of apples Mary had.\n",
      "Action: Calculator\n",
      "Action Input: 4 + 20\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 24\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe final answer is 24 apples. \n",
      "Final Answer: 24 apples.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'if Mary has four apples and Giorgio brings two and a half apple boxes (apple box contains eight apples), how many apples do we have?',\n",
       " 'output': '24 apples.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"if Mary has four apples and Giorgio brings two and a half apple \"\n",
    "                \"boxes (apple box contains eight apples), how many apples do we \"\n",
    "                \"have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d852f82",
   "metadata": {},
   "source": [
    "A more common case is we add a basic llm chain and plus all other tools, so that if additional tools are not useful, it will default to use llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fcba917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"{query}\"\n",
    ")\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "# initialize the LLM tool\n",
    "llm_tool = Tool(\n",
    "    name='Language Model',\n",
    "    func=llm_chain.run,\n",
    "    description='use this tool for general purpose queries and logic'\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10e3f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add llm tool to tool list \n",
    "tools.append(llm_tool)\n",
    "\n",
    "## initiate the zero shot agent again \n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ff0cd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI don't know the answer to this question off the top of my head, so I should use a language model to search for it.\n",
      "Action: Language Model\n",
      "Action Input: \"What is the capital of Norway?\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mThe capital of Norway is Oslo.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the answer to the question.\n",
      "Final Answer: Oslo is the capital of Norway.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the capital of Norway?',\n",
       " 'output': 'Oslo is the capital of Norway.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now try it out \n",
    "zero_shot_agent(\"what is the capital of Norway?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "194c41f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI should use the calculator for this math problem.\n",
      "Action: Calculator\n",
      "Action Input: (4.5*2.1)^2.2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 139.94261298333066\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the answer to the math problem.\n",
      "Final Answer: 139.94261298333066\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is (4.5*2.1)^2.2?', 'output': '139.94261298333066'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## give it a simple try \n",
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e498626a",
   "metadata": {},
   "source": [
    "#### There are a lot prebuilt tools in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70181627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bff4245c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Calculator', 'Useful for when you need to answer questions about math.')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools[0].name,tools[0].description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb0bce",
   "metadata": {},
   "source": [
    "## What is an agent?\n",
    "**Definition**: The key behind agents is giving LLM's the possibility of using tools in their workflow. This is where langchain departs from the popular chatgpt implementation and we can start to get a glimpse of what it offers us as builders. Until now, we covered several building blocks in isolation. Let's see them come to life.\n",
    "\n",
    "The official definition of agents is the following:\n",
    "\n",
    "\n",
    "> Agents use an LLM to determine which actions to take and in what order. An action can either be using a tool and observing its output, or returning to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbb4e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def count_tokens(agent, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = agent(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd302906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "Language Model: use this tool for general purpose queries and logic\n",
      "Language Model: use this tool for general purpose queries and logic\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Calculator, Language Model, Language Model]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(zero_shot_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa1b8c2",
   "metadata": {},
   "source": [
    "### see [here](https://github.com/pinecone-io/examples/blob/master/generation/langchain/handbook/06-langchain-agents.ipynb) for an example of combining sql agent together with calculator to perform a task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8c17e",
   "metadata": {},
   "source": [
    "Suffice it to say for now that **the LLM now has the ability to 'reason' on how to best use tools** to solve our query and can combine them in intelligent ways with just a brief description of each of them. If you want to learn more about this paradigm (MRKL) in detail, please refer to [this](https://arxiv.org/pdf/2205.00445.pdf) paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a0f21",
   "metadata": {},
   "source": [
    "Finally, let's pay attention to the 'agent_scratchpad'. What is that? Well, that is where we will be appending every thought or action that the agent has already performed. In this way, at each point in time, the agent will know what it has found out and will be able to continue its thought process. In other words, after using a tool it adds its thoughts and observations to the scratchpad and picks up from there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60145a10",
   "metadata": {},
   "source": [
    "### Agent type #2: Conversational React"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe291a0f",
   "metadata": {},
   "source": [
    "The zero shot agent is really interesting but, as we said before, it has no memory. What if we want an assistant that remembers things we have talked about and can also reason about them and use tools? For that we have the conversational react agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b8fcc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "conversational_agent = initialize_agent(\n",
    "    agent='conversational-react-description', \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ede38a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: I'm sorry, but I don't have access to real-time stock prices. However, you can check financial news websites or use a stock market app to get the latest stock prices for ABC on January 1st.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 446 tokens\n"
     ]
    }
   ],
   "source": [
    "result = count_tokens(\n",
    "    conversational_agent, \n",
    "    \"Please provide me the stock prices for ABC on January the 1st\"\n",
    "                     )\n",
    "\n",
    "## we did not add db query tool here, so it won't work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c78f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cf887a0cd63b1646b72eb9cdb014d6c9733a8a0a6989a432f0f7542bfe6547e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
