{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ISR Approach 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys # ,getpass\n",
    "sys.path.insert(0,'../../libs')\n",
    "import pandas as pd \n",
    "from utils import load_json, extract_json_string,get_all_files\n",
    "from oai_ast_utils import OpenAIAssistant_Base\n",
    "import tqdm,json,time\n",
    "#from openai import OpenAI\n",
    "## load API Key\n",
    "key = load_json('/root/workspace/key/openai_key.json') \n",
    "os.environ['OPENAI_API_KEY'] = key['ChatGPT1']['API_KEY']\n",
    "#os.environ['OPENAI_API_KEY'] = key['ISR']['API_KEY']\n",
    "#os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(prompt='OpenAI API Token:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELETE_FILES = False\n",
    "UPLOAD_FILES = True\n",
    "CREATE_AST = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initiate agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ISRBot = OpenAIAssistant_Base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all files and upload them \n",
    "- if already done so, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_folder = '/root/workspace/data/DOCs/PDF'\n",
    "res_folder = '/root/workspace/data/ISR_Results'\n",
    "all_pdfs = get_all_files(PDF_folder,end_with='.pdf')\n",
    "file_names = [os.path.basename(f) for f in all_pdfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if it is the fist time do it. Before upload, remove all existing files first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['file-AJd4ejfVOhyTKC4CXJjlLQDD', 'file-zrAaLSb2gch6PwhXrbqWFP0x', 'file-0IovNjuAFjxEXjkIqrQ6Vga6'] has been removed from file server.\n",
      "files deleted ['file-AJd4ejfVOhyTKC4CXJjlLQDD', 'file-zrAaLSb2gch6PwhXrbqWFP0x', 'file-0IovNjuAFjxEXjkIqrQ6Vga6']\n",
      "                              id    bytes  created_at            filename  \\\n",
      "0  file-USdjzVAJgclWyxxtYc4tIiUO  3466567  1704572287        USA_2022.pdf   \n",
      "1  file-fRXHBzeSfTYhcu82NfZ5MlL8  3966712  1704572286        UAE_2021.pdf   \n",
      "2  file-SEKf1SIkmnacDs70Cpfodz5j  2540360  1704572285   Tanzania_2023.pdf   \n",
      "3  file-8QD58MFCIiObTdKB2U5hh5ON  7302895  1704572283  Indonesia_2023.pdf   \n",
      "4  file-qWu8glM3tmEn3ymRwbRO3WXo  2814763  1704572281    Belgium_2022.pdf   \n",
      "\n",
      "  object     purpose     status status_details  \n",
      "0   file  assistants  processed           None  \n",
      "1   file  assistants  processed           None  \n",
      "2   file  assistants  processed           None  \n",
      "3   file  assistants  processed           None  \n",
      "4   file  assistants  processed           None  \n"
     ]
    }
   ],
   "source": [
    "if UPLOAD_FILES:\n",
    "    \n",
    "    if DELETE_FILES:\n",
    "    # clear all previous files \n",
    "        filter_criteria={} #USA_2022.pdf\n",
    "        sampled_file_ids = ISRBot.FileManager.get_files_info_by(filter_criteria,return_fields=['id'],to_dict=True,to_single_list=True)\n",
    "        ISRBot.FileManager.delete_files_by_ids(file_ids=sampled_file_ids)\n",
    "        print('files deleted {}'.format(sampled_file_ids))\n",
    "    \n",
    "    ## upload files get files ids\n",
    "    files_list = []\n",
    "    for fp in all_pdfs:\n",
    "        fid,fname = ISRBot.FileManager.upload_file(fp,purpose='assistants')\n",
    "        files_list.append((fid,fname))\n",
    "        \n",
    "    print(ISRBot.FileManager._get_file_info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- upload all files and get file name and ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if the first time run it, create a ISR Bot first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_AST: \n",
    "    ISRBot.create_assistant(name='ISR Bot',\n",
    "                        description='This bot is created to help ISR project',\n",
    "                        instructions=\"You are an economist in the IMF. Your main task is to review Country Staff reports.\")\n",
    "    print(ISRBot.assistant.name , ISRBot.assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if the bot is already there, load and activate the assistant "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load all needed files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'file-USdjzVAJgclWyxxtYc4tIiUO', 'filename': 'USA_2022.pdf'}, {'id': 'file-fRXHBzeSfTYhcu82NfZ5MlL8', 'filename': 'UAE_2021.pdf'}, {'id': 'file-SEKf1SIkmnacDs70Cpfodz5j', 'filename': 'Tanzania_2023.pdf'}, {'id': 'file-8QD58MFCIiObTdKB2U5hh5ON', 'filename': 'Indonesia_2023.pdf'}, {'id': 'file-qWu8glM3tmEn3ymRwbRO3WXo', 'filename': 'Belgium_2022.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "loop_files = ISRBot.FileManager.get_files_info_by(filter_criteria={'filename':file_names},return_fields=['id','filename'],to_dict=True)\n",
    "print(loop_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_identify_risks = \"\"\"\n",
    "You are an economist in the IMF. Your main task is to review Country Staff reports. Please identify at least 8 major macro critical risks described in the document. Please provide detailed description of each risks. Please return all identified risks in a JSON object.\n",
    "\n",
    "Output is a JSON object with the following format: {{\"risks\": [ {{\"risk_name\": \"\", \"risk_description\": \"<risk_description1>\"}}, {{\"risk_name\": \"\", \"risk_description\": \"<risk_description2>\"}}, ...... ]}}\n",
    "\n",
    "Please proceed with the task, keeping in mind the importance of accuracy and clarity in your analysis.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asst_4oWbFLPVW77u9qbxFcLSlklb']\n",
      "ISR Bot asst_4oWbFLPVW77u9qbxFcLSlklb\n",
      "set ISR Bot as current active assistant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 30.78 s || Status: completed      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:38<02:32, 38.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 28.75 s || Status: completed      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:13<01:48, 36.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 56.97 s || Status: completed      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [02:18<01:39, 49.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 40.71 s || Status: completed      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [03:07<00:49, 49.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 34.58 s || Status: completed      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:48<00:00, 45.69s/it]\n"
     ]
    }
   ],
   "source": [
    "## reload assistant ; sometime there are bugs if keep reusing the same assistant\n",
    "filter_criteria={'name':['ISR Bot']}\n",
    "as_id = ISRBot.get_assistants_info_by(filter_criteria,return_fields=['id'])\n",
    "print(as_id)\n",
    "## retrieve by id \n",
    "assit = ISRBot.get_assistants_by_ids(as_id[0])\n",
    "print(assit.name, assit.id )\n",
    "## set the retrieved assistant as current active assistant \n",
    "ISRBot._set_active_assistant(assit)\n",
    "\n",
    "#for fid,fname in files_list:\n",
    "results = {}\n",
    "for f_dict in tqdm.tqdm(loop_files):\n",
    "## update assistant file with specific country file \n",
    "    fid,fname = f_dict.get('id'),f_dict.get('filename')\n",
    "    ass_info_dict = {\n",
    "                'model':\"gpt-4-1106-preview\",\n",
    "                'file_ids':[fid] ### USA file id\n",
    "                }\n",
    "    ISRBot.update_current_assistant(**ass_info_dict)\n",
    "    \n",
    "    user_input_dict = {\"role\":\"user\",\n",
    "                    \"content\":prompt_identify_risks\n",
    "                    }\n",
    "    msg,status = ISRBot.quick_query(user_input_dict)\n",
    "    results[fname]={'msg':msg,'status':status}\n",
    "    time.sleep(2)\n",
    "    #print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(res_folder,'raw_msg.json'), 'w') as file:\n",
    "    json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- post process outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load file \n",
    "results = load_json(os.path.join(res_folder,'raw_msg.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_out = {}\n",
    "for k,v in results.items():\n",
    "    try:\n",
    "        res_list = json.loads(extract_json_string(results[k]['msg']))['risks']\n",
    "        res_df = pd.DataFrame(res_list)\n",
    "        excel_out[k] = res_df\n",
    "    except:\n",
    "        \n",
    "        print('error:{}'.format(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_out_path = os.path.join(res_folder,'risks.xlsx')\n",
    "with pd.ExcelWriter(excel_out_path, engine='openpyxl') as writer:\n",
    "    # Write each DataFrame to a different sheet\n",
    "    for k,df in excel_out.items():\n",
    "        df.to_excel(writer, sheet_name=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
