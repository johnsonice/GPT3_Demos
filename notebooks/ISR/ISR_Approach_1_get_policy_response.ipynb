{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ISR Approach 1 get policy response "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys # ,getpass\n",
    "sys.path.insert(0,'../../libs')\n",
    "import pandas as pd \n",
    "from utils import load_json, extract_json_string,get_all_files\n",
    "from oai_ast_utils import OpenAIAssistant_Base\n",
    "import tqdm,json,time\n",
    "#from openai import OpenAI\n",
    "## load API Key\n",
    "key = load_json('/root/workspace/key/openai_key.json') \n",
    "os.environ['OPENAI_API_KEY'] = key['ChatGPT1']['API_KEY']\n",
    "#os.environ['OPENAI_API_KEY'] = key['ISR']['API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>bytes</th>\n",
       "      <th>created_at</th>\n",
       "      <th>filename</th>\n",
       "      <th>object</th>\n",
       "      <th>purpose</th>\n",
       "      <th>status</th>\n",
       "      <th>status_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file-USdjzVAJgclWyxxtYc4tIiUO</td>\n",
       "      <td>3466567</td>\n",
       "      <td>1704572287</td>\n",
       "      <td>USA_2022.pdf</td>\n",
       "      <td>file</td>\n",
       "      <td>assistants</td>\n",
       "      <td>processed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file-fRXHBzeSfTYhcu82NfZ5MlL8</td>\n",
       "      <td>3966712</td>\n",
       "      <td>1704572286</td>\n",
       "      <td>UAE_2021.pdf</td>\n",
       "      <td>file</td>\n",
       "      <td>assistants</td>\n",
       "      <td>processed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file-SEKf1SIkmnacDs70Cpfodz5j</td>\n",
       "      <td>2540360</td>\n",
       "      <td>1704572285</td>\n",
       "      <td>Tanzania_2023.pdf</td>\n",
       "      <td>file</td>\n",
       "      <td>assistants</td>\n",
       "      <td>processed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file-8QD58MFCIiObTdKB2U5hh5ON</td>\n",
       "      <td>7302895</td>\n",
       "      <td>1704572283</td>\n",
       "      <td>Indonesia_2023.pdf</td>\n",
       "      <td>file</td>\n",
       "      <td>assistants</td>\n",
       "      <td>processed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file-qWu8glM3tmEn3ymRwbRO3WXo</td>\n",
       "      <td>2814763</td>\n",
       "      <td>1704572281</td>\n",
       "      <td>Belgium_2022.pdf</td>\n",
       "      <td>file</td>\n",
       "      <td>assistants</td>\n",
       "      <td>processed</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id    bytes  created_at            filename  \\\n",
       "0  file-USdjzVAJgclWyxxtYc4tIiUO  3466567  1704572287        USA_2022.pdf   \n",
       "1  file-fRXHBzeSfTYhcu82NfZ5MlL8  3966712  1704572286        UAE_2021.pdf   \n",
       "2  file-SEKf1SIkmnacDs70Cpfodz5j  2540360  1704572285   Tanzania_2023.pdf   \n",
       "3  file-8QD58MFCIiObTdKB2U5hh5ON  7302895  1704572283  Indonesia_2023.pdf   \n",
       "4  file-qWu8glM3tmEn3ymRwbRO3WXo  2814763  1704572281    Belgium_2022.pdf   \n",
       "\n",
       "  object     purpose     status status_details  \n",
       "0   file  assistants  processed           None  \n",
       "1   file  assistants  processed           None  \n",
       "2   file  assistants  processed           None  \n",
       "3   file  assistants  processed           None  \n",
       "4   file  assistants  processed           None  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ISRBot = OpenAIAssistant_Base()\n",
    "ISRBot.FileManager._get_file_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load file \n",
    "res_folder = '/root/workspace/data/ISR_Results'\n",
    "PDF_folder = '/root/workspace/data/DOCs/PDF'\n",
    "results = load_json(os.path.join(res_folder,'raw_msg.json'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- first check see if all needed files are there "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "needed files : ['USA_2022.pdf', 'UAE_2021.pdf', 'Tanzania_2023.pdf', 'Indonesia_2023.pdf', 'Belgium_2022.pdf']\n"
     ]
    }
   ],
   "source": [
    "file_names = list(results.keys())\n",
    "print('needed files : {}'.format(file_names))\n",
    "server_file_info = ISRBot.FileManager.get_files_info_by(filter_criteria={'filename':file_names},return_fields=['filename'])\n",
    "for fn in file_names:\n",
    "    if fn not in server_file_info:\n",
    "        fp = os.path.join(PDF_folder,fn)\n",
    "        fid,fname = ISRBot.FileManager.upload_file(fp,purpose='assistants')\n",
    "        print('uploaded {}'.format(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get all files need to be processed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'file-USdjzVAJgclWyxxtYc4tIiUO', 'filename': 'USA_2022.pdf'}, {'id': 'file-fRXHBzeSfTYhcu82NfZ5MlL8', 'filename': 'UAE_2021.pdf'}, {'id': 'file-SEKf1SIkmnacDs70Cpfodz5j', 'filename': 'Tanzania_2023.pdf'}, {'id': 'file-8QD58MFCIiObTdKB2U5hh5ON', 'filename': 'Indonesia_2023.pdf'}, {'id': 'file-qWu8glM3tmEn3ymRwbRO3WXo', 'filename': 'Belgium_2022.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "loop_files = ISRBot.FileManager.get_files_info_by(filter_criteria={'filename':file_names},return_fields=['id','filename'],to_dict=True)\n",
    "print(loop_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process raw mesg and formulate prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_res = {k:json.loads(extract_json_string(v['msg'])) for k,v in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_dicts=processed_res['USA_2022.pdf']['risks']\n",
    "# def dict2string(list_of_dicts):\n",
    "#     result_string = \"\"\n",
    "#     for d in list_of_dicts:\n",
    "#         for key, value in d.items():\n",
    "#             result_string += f\"{key}: {value}, \"\n",
    "#         result_string = result_string.rstrip(', ') + '; \\n'\n",
    "#     return result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_identify_policy = \"\"\"\n",
    "You are an economist in the IMF. Your main task is to review Country Staff reports.\n",
    "Please read carefully the document and the listed macro critical risk and its description. \n",
    "From the document, please identify all suggested policy responses to mitigate this specific risk listed. \n",
    "Please make sure you only provide policy responses directly targeted at this specific risk. \n",
    "Please only use content in the provided document and nothing else.\n",
    "\n",
    "The identified risks below:\n",
    "\n",
    "----------\n",
    "\n",
    "{RISK_ITEM}\n",
    "\n",
    "----------\n",
    "\n",
    "Output is a JSON object with the following format: {{\"risk_name\": \"<risk_name>\", \"risk_description\": \"<risk_description>\", \"policy_responses\":[\"<policy response1>\",\"<policy response2>\", ...... ]}}\n",
    "\n",
    "Please proceed with the task, keeping in mind the importance of accuracy and clarity in your analysis.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- print one example of prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are an economist in the IMF. Your main task is to review Country Staff reports.\n",
      "Please read carefully the document and the listed macro critical risk and its description. \n",
      "From the document, please identify all suggested policy responses to mitigate this specific risk listed. \n",
      "Please make sure you only provide policy responses directly targeted at this specific risk. \n",
      "Please only use content in the provided document and nothing else.\n",
      "\n",
      "The identified risks below:\n",
      "\n",
      "----------\n",
      "\n",
      "Russia’s Invasion of Ukraine: Escalation of sanctions and other disruptions due to Russia’s invasion of Ukraine could lead to even higher commodity prices, refugee migration, tighter financial conditions, and other adverse spillovers that particularly affect Low-Income Countries (LICs) and commodity-importing Emerging Markets (EMs)【9†source】.\n",
      "\n",
      "----------\n",
      "\n",
      "Output is a JSON object with the following format: {\"risk_name\": \"<risk_name>\", \"risk_description\": \"<risk_description>\", \"policy_responses\":[\"<policy response1>\",\"<policy response2>\", ...... ]}\n",
      "\n",
      "Please proceed with the task, keeping in mind the importance of accuracy and clarity in your analysis.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_dicts=processed_res['USA_2022.pdf']['risks']\n",
    "risk_items = [\"{}: {}\".format(i.get('risk_name'),i.get('risk_description')) for i in list_of_dicts]\n",
    "print(prompt_identify_policy.format(RISK_ITEM = risk_items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_AST = False\n",
    "if CREATE_AST: \n",
    "    ISRBot.create_assistant(name='ISR Bot',\n",
    "                        description='This bot is created to help ISR project',\n",
    "                        instructions=\"You are an economist in the IMF. Your main task is to review Country Staff reports.\")\n",
    "    print(ISRBot.assistant.name , ISRBot.assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asst_4oWbFLPVW77u9qbxFcLSlklb']\n",
      "ISR Bot asst_4oWbFLPVW77u9qbxFcLSlklb\n",
      "set ISR Bot as current active assistant.\n"
     ]
    }
   ],
   "source": [
    "## reload assistant ; sometime there are bugs if keep reusing the same assistant\n",
    "filter_criteria={'name':['ISR Bot']}\n",
    "as_id = ISRBot.get_assistants_info_by(filter_criteria,return_fields=['id'])\n",
    "print(as_id)\n",
    "## retrieve by id \n",
    "assit = ISRBot.get_assistants_by_ids(as_id[0])\n",
    "print(assit.name, assit.id )\n",
    "## set the retrieved assistant as current active assistant \n",
    "ISRBot._set_active_assistant(assit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now run policy identification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 19.46 s || Status: completed      "
     ]
    }
   ],
   "source": [
    "results_policy={}\n",
    "for f_dict in loop_files:\n",
    "    # f_dict = loop_files[0]\n",
    "    fid,fname = f_dict.get('id'),f_dict.get('filename')\n",
    "    ass_info_dict = {\n",
    "                'model':\"gpt-4-1106-preview\",\n",
    "                'file_ids':[fid] ### USA file id\n",
    "                }\n",
    "    ISRBot.update_current_assistant(**ass_info_dict)\n",
    "    \n",
    "    ## run the query \n",
    "    results_policy[fname] = []\n",
    "    list_of_dicts=processed_res[fname]['risks']\n",
    "    risk_items = [\"{}: {}\".format(i.get('risk_name'),i.get('risk_description')) for i in list_of_dicts]\n",
    "    \n",
    "    for ri in risk_items:\n",
    "        user_input_dict = {\"role\":\"user\",\n",
    "                        \"content\":prompt_identify_policy.format(RISK_ITEM = ri)\n",
    "                        }\n",
    "        msg,status = ISRBot.quick_query(user_input_dict)\n",
    "        results_policy[fname].append({'msg':msg,'status':status})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "### export raw policy response to json \n",
    "with open(os.path.join(res_folder,'raw_policy_response_msg.json'), 'w') as file:\n",
    "    json.dump(results_policy, file, indent=4)\n",
    "    \n",
    "#### post process raw results \n",
    "processed_policy_res = {}\n",
    "for fn,vs in results_policy.items():\n",
    "    processed_policy_res[fn]=[]\n",
    "    for v in vs:\n",
    "        try:\n",
    "            temp_res = json.loads(extract_json_string(v['msg']))\n",
    "            processed_policy_res[fn].append(temp_res)\n",
    "        except:\n",
    "            print('error {}'.format(v))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dfs = {}\n",
    "excel_out_path = os.path.join(res_folder,'policy.xlsx')\n",
    "with pd.ExcelWriter(excel_out_path, engine='openpyxl') as writer:\n",
    "    for k,v in processed_policy_res.items():\n",
    "        t_df = pd.DataFrame(v)\n",
    "        expanded_df = t_df.explode('policy_responses')\n",
    "        expanded_df.to_excel(writer, sheet_name=k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
