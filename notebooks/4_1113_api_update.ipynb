{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI 1113 api update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0,'../libs')\n",
    "import time\n",
    "from utils import load_json,logging,exception_handler\n",
    "from llm_utils import get_oai_fees\n",
    "import json\n",
    "## load API Key\n",
    "\n",
    "key = load_json('/root/workspace/Dev/openai_key.json') \n",
    "os.environ['OPENAI_API_KEY'] = key['ChatGPT1']['API_KEY']\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a base openai agent class \n",
    "class BSAgent():\n",
    "    def __init__(self, api_key=None, \n",
    "                 model=\"gpt-3.5-turbo-1106\", \n",
    "                 temperature=0):\n",
    "\n",
    "        if not api_key:\n",
    "            api_key = os.environ['OPENAI_API_KEY']\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.temperature = temperature\n",
    "        if model:\n",
    "            self.model = model\n",
    "        self.message = []\n",
    "\n",
    "    def _add_messages_history(self, response) -> None:\n",
    "\n",
    "        self.message.append(response[\"choices\"][0][\"message\"])\n",
    "\n",
    "    @exception_handler(error_msg='Failed with multiple retry',\n",
    "                        error_return=None,\n",
    "                        attempts=3,delay=5)\n",
    "    def get_completion(self,\n",
    "                       prompt_template, \n",
    "                       model=None,\n",
    "                       temperature=None,\n",
    "                       conv_history=[],\n",
    "                       return_cost=False,\n",
    "                       verbose=True,\n",
    "                       stream=False):\n",
    "        if not model:\n",
    "            model = self.model\n",
    "        \n",
    "        if not temperature:\n",
    "            temperature = self.temperature\n",
    "        \n",
    "        new_message = []\n",
    "        if prompt_template.get('System'):\n",
    "            new_message.append({\"role\": \"system\", \"content\": prompt_template['System']})\n",
    "        if prompt_template.get('Human'):\n",
    "            new_message.append({\"role\": \"user\", \"content\": prompt_template['Human']})\n",
    "        \n",
    "        conv_history.extend(new_message)\n",
    "        \n",
    "        if len(conv_history) == 0 :\n",
    "            raise Exception('prompt template error, prompt must be a dict with with System message or Human message.')\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=conv_history,\n",
    "                    temperature=temperature,\n",
    "                    stream=stream\n",
    "                )\n",
    "        \n",
    "        if not stream:\n",
    "            prompt_tokens = response.usage.prompt_tokens\n",
    "            completion_tokens = response.usage.completion_tokens\n",
    "            this_time_price = get_oai_fees(model, prompt_tokens, completion_tokens)\n",
    "            if verbose:\n",
    "                logging.info(f\"************|||----|||price: {this_time_price}|||----|||************\")\n",
    "        \n",
    "        if return_cost:\n",
    "            return response,this_time_price\n",
    "        \n",
    "        return response \n",
    "    \n",
    "    def get_response_content(self,**kwargs):\n",
    "        response = self.get_completion(**kwargs)\n",
    "        res_msg = response.choices[0].message.content\n",
    "        return res_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate an llm agent\n",
    "llm_agent = BSAgent(model=\"gpt-3.5-turbo-1106\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm an AI language model and don't have a personal name. You can just call me Assistant. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "pt = {'System':'You are a helpful assistant.',\n",
    "      'Human':'What is your name?'}\n",
    "res = llm_agent.get_response_content(prompt_template=pt)\n",
    "print(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a helpful assistant here to answer your questions and assist you with tasks. You can call me \"Assistant.\"None"
     ]
    }
   ],
   "source": [
    "completion = llm_agent.get_completion(prompt_template=pt,stream=True)\n",
    "for chunk in completion:\n",
    "  print(chunk.choices[0].delta.content,end=\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch complete\n",
    "- https://platform.openai.com/docs/guides/rate-limits/batching-requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4 vision preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='The image shows a scenic natural landscape featuring a wooden boardwalk extending across a green grassy field. The boardwalk leads towards the horizon and seems to provide a path through the high grass, perhaps in a wetland or marsh area. The sky is partly cloudy with fluffy blue and white clouds, suggesting it is either a late afternoon or a tranquil morning. The greenery and the clear sky contribute to the serenity of the landscape. There are also some shrubs or bushes and a few trees scattered in the distance, accentuating the diverse vegetation of the area. The image exudes a sense of peace and might be used to depict topics related to nature walks, conservation areas, wetlands, or the beauty of untouched landscapes.', role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'stop', 'stop': '<|fim_suffix|>'})\n"
     ]
    }
   ],
   "source": [
    "response = llm_agent.client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Assistnat API Demo\n",
    "- ### Assistant API for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-0IovNjuAFjxEXjkIqrQ6Vga6\n"
     ]
    }
   ],
   "source": [
    "## upload a file \n",
    "sample_file = '/home/chengyu.huang/project/Fund_projects/temp_data/174_638_R0.pdf'\n",
    "assert os.path.exists(sample_file)\n",
    "file = client.files.create(\n",
    "    file=open(sample_file,'rb'),\n",
    "    purpose='assistants'\n",
    ")\n",
    "print(file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[FileObject](data=[FileObject(id='file-0IovNjuAFjxEXjkIqrQ6Vga6', bytes=1726558, created_at=1699990845, filename='174_638_R0.pdf', object='file', purpose='assistants', status='processed', status_details=None)], object='list', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "# list out existing files \n",
    "file_list = client.files.list()\n",
    "print(file_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the assistant, give it access to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asst_S7tADW8enJ07mcZt11hSOgzx\n"
     ]
    }
   ],
   "source": [
    "# Add the file to the assistant \n",
    "file_id = file_list.data[0].id\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a chatbot designed to respond to enquires about the IMF lending program. Use your knowledge base to best respond to user questions\",\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    tools=[{\"type\":\"retrieval\"}],\n",
    "    file_ids = [file_id]\n",
    ")\n",
    "## you can use client.beta.assistants.update if you need to change some of the settings\n",
    "print(assistant.id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also retrieve an existing assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assistant(id='asst_S7tADW8enJ07mcZt11hSOgzx', created_at=1699990853, description=None, file_ids=['file-0IovNjuAFjxEXjkIqrQ6Vga6'], instructions='You are a chatbot designed to respond to enquires about the IMF lending program. Use your knowledge base to best respond to user questions', metadata={}, model='gpt-3.5-turbo-1106', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])]\n"
     ]
    }
   ],
   "source": [
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\"\n",
    ")\n",
    "print(my_assistants.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_S7tADW8enJ07mcZt11hSOgzx', created_at=1699990853, description=None, file_ids=['file-0IovNjuAFjxEXjkIqrQ6Vga6'], instructions='You are a chatbot designed to respond to enquires about the IMF lending program. Use your knowledge base to best respond to user questions', metadata={}, model='gpt-3.5-turbo-1106', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "## retrieive a assistant \n",
    "assistant_id = my_assistants.data[0].id\n",
    "assistant = client.beta.assistants.retrieve(assistant_id)\n",
    "print(assistant)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an empty thread and add message to the thread and run the assistant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_eWfRuMQm2RFhMT4DrciYFzO8', created_at=1699990941, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create message and add to the thread \n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Can you list the conditionalities required in the imf program\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_SorRFLhD2CGH4e4sfOFBFGBn\n"
     ]
    }
   ],
   "source": [
    "## run the assistant \n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id,\n",
    "    instructions=\"Please address the user as Huang. Do not provide an answer if no usefule infomation was retrieved from konwledge base.\"\n",
    ")\n",
    "\n",
    "print(run.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n"
     ]
    }
   ],
   "source": [
    "## retrieve the result \n",
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[RunStep](data=[RunStep(id='step_xxYp8F1qsSr5kYwZc8FXX79N', assistant_id='asst_S7tADW8enJ07mcZt11hSOgzx', cancelled_at=None, completed_at=1699990947, created_at=1699990944, expired_at=None, failed_at=None, last_error=None, metadata=None, object='thread.run.step', run_id='run_iX4jsjgKM7arTXqiIOmKw1Tu', status='completed', step_details=MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_jk1C9PXMX7gUl2zXXjgGp3qj'), type='message_creation'), thread_id='thread_eWfRuMQm2RFhMT4DrciYFzO8', type='message_creation', expires_at=None), RunStep(id='step_EwMQMwdvEeutVglYS6O7eyEK', assistant_id='asst_S7tADW8enJ07mcZt11hSOgzx', cancelled_at=None, completed_at=1699990944, created_at=1699990943, expired_at=None, failed_at=None, last_error=None, metadata=None, object='thread.run.step', run_id='run_iX4jsjgKM7arTXqiIOmKw1Tu', status='completed', step_details=ToolCallsStepDetails(tool_calls=[RetrievalToolCall(id='call_OFhhc0AJ2DKPloJ3HRqwVZx3', retrieval={}, type='retrieval')], type='tool_calls'), thread_id='thread_eWfRuMQm2RFhMT4DrciYFzO8', type='tool_calls', expires_at=None)], object='list', first_id='step_xxYp8F1qsSr5kYwZc8FXX79N', last_id='step_EwMQMwdvEeutVglYS6O7eyEK', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "## list out run steps \n",
    "# run_steps = client.beta.threads.runs.steps.list(\n",
    "#     thread_id = thread.id,\n",
    "#     run_id = run.id\n",
    "# )\n",
    "# print(run_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### how to cancle a run \n",
    "# run = client.beta.threads.runs.cancel(\n",
    "#     thread_id=thread.id,\n",
    "#     run_id = run.id\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: It seems that the specific list of conditionalities is not explicitly stated in the document. If there are any specific terms, policy measures, or requirements related to the IMF program that you would like me to look for, please let me know and I can conduct a search for those specific details.\n",
      "=============\n",
      "assistant: I'm unable to retrieve the specific conditionalities from the document using the quote function. Let me try another approach to locate the details.\n",
      "=============\n",
      "user: Can you list the conditionalities required in the imf program\n",
      "=============\n",
      "assistant: The document provides a summary of the conditionalities related to the request for a Stand-By Arrangement for Greece. Here are the main elements of the program:\n",
      "\n",
      "1. Greece is adopting an ambitious comprehensive multi-year adjustment program to lower the fiscal deficit and the debt ratio, reduce domestic demand in line with capacity, and increase supply and competitiveness.\n",
      "2. The requested Stand-By Arrangement is for €30 billion with an initial purchase of €5.5 billion available upon Board approval, and euro-zone partner countries are prepared to commit €80 billion with a first disbursement of €14.5 billion.\n",
      "3. Fiscal policy is frontloaded with measures of 7½ percent of GDP in 2010, 4 percent of GDP in 2011, and 2 percent of GDP in 2012 and 2013 each to turn around the fiscal position and help place the debt ratio on a downward path.\n",
      "4. The program includes provisions to shield low-income households from the brunt of the adjustment effort, and a Financial Stability Fund will be established to ensure adequate capitalization of the banking system.\n",
      "5. Coordination with the European Commission and the European Central Bank on program implementation and financing will be crucial to the success of the program.\n",
      "6. Risks to the program are high, and Greece needs to persevere to ensure continued international support.\n",
      "\n",
      "This provides an overview of the conditionalities outlined in the document. If you need more specific details or further analysis, please let me know.\n",
      "=============\n",
      "user: Can you sumarize the conditionalities\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "## retrieve the message \n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "for each in messages:\n",
    "  print(each.role+\": {}\".format(each.content[0].text.value))\n",
    "  print(\"=============\")\n",
    "##print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Post test clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assistant(id='asst_S7tADW8enJ07mcZt11hSOgzx', created_at=1699990853, description=None, file_ids=['file-0IovNjuAFjxEXjkIqrQ6Vga6'], instructions='You are a chatbot designed to respond to enquires about the IMF lending program. Use your knowledge base to best respond to user questions', metadata={}, model='gpt-3.5-turbo-1106', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])]\n"
     ]
    }
   ],
   "source": [
    "my_assistants = client.beta.assistants.list(\n",
    "    order='desc',\n",
    "    limit=\"20\"\n",
    ")\n",
    "print(my_assistants.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssistantDeleted(id='asst_S7tADW8enJ07mcZt11hSOgzx', deleted=True, object='assistant.deleted')\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.assistants.delete('asst_S7tADW8enJ07mcZt11hSOgzx')\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Assistnat API, function call\n",
    "- give the assistant additional tools \n",
    "- example : https://medium.com/@assafelovic/how-to-build-an-openai-assistant-with-internet-browsing-ee5ad7625661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174_638_R0.pdf\n",
      "file-0IovNjuAFjxEXjkIqrQ6Vga6\n"
     ]
    }
   ],
   "source": [
    "# list out existing files , get the firt file id \n",
    "file_list = client.files.list()\n",
    "print(file_list.data[0].filename)\n",
    "file_id = file_list.data[0].id\n",
    "print(file_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define some customized functions\n",
    "- Here is an example of a web search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some demo function descriptions to register in openai\n",
    "web_search ={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"web_search\",\n",
    "            \"description\": \"Get information on recent events from the web.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"The search query to use. For example: 'Latest news on Nvidia stock performance'\"},\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "get_whether={\n",
    "      \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"getCurrentWeather\",\n",
    "      \"description\": \"Get the weather in location\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"},\n",
    "          \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}\n",
    "        },\n",
    "        \"required\": [\"location\"]\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "assistant_prompt_instruction = \"\"\"You are an expert on IMF programs. \n",
    "Your goal is to provide answers based on information from the internet and the knowledge base. \n",
    "You must use the provided web search function to find relevant online information. \n",
    "On top of web info, you should also use your own knowledge to answer questions.\n",
    "Please include relevant url sources in the end of your answers.\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create an assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asst_R2EUD7DAltjLs8CNCHK2Nbz1\n"
     ]
    }
   ],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    instructions=assistant_prompt_instruction,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    tools=[{\"type\":\"retrieval\"},\n",
    "           web_search,\n",
    "           ],\n",
    "    file_ids=[file_id]\n",
    ")\n",
    "print(assistant.id)\n",
    "# response = client.beta.assistants.delete(assistant.id)\n",
    "# print(response)\n",
    "# you can use client.beta.assistants.update\n",
    "# or client.beta.assistants.retrieve\n",
    "# for reuse existing assistant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a thread and run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = 'what is the most recent developments on the program?' #input(\"You: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_1aX1XfBfTzrGqMwrQJ3pJDIG\n"
     ]
    }
   ],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    ")\n",
    "print(run.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run status: requires_action\n"
     ]
    }
   ],
   "source": [
    "# Function to wait for a run to complete\n",
    "def wait_for_run_completion(thread_id, run_id):\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "        print(f\"Current run status: {run.status}\")\n",
    "        if run.status in ['completed', 'failed', 'requires_action']:\n",
    "            return run\n",
    "\n",
    "run = wait_for_run_completion(thread.id,run.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RequiredActionFunctionToolCall(id='call_FJ8YfNR7IzXlG30zFop0yPGZ', function=Function(arguments='{\"query\":\"latest IMF program updates April 2023\"}', name='web_search'), type='function')]\n",
      "function name: web_search\n"
     ]
    }
   ],
   "source": [
    "tools_to_call = run.required_action.submit_tool_outputs.tool_calls\n",
    "print(tools_to_call)\n",
    "print('function name: {}'.format(tools_to_call[0].function.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search_func(q):\n",
    "    \"\"\"\n",
    "    a dummy websearch function for testing purpose\n",
    "    \"\"\"\n",
    "    res = \"there isn't much new developments on the program.\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to handle tool output submission\n",
    "def submit_tool_outputs(tools_to_call):\n",
    "    tool_output_array = []\n",
    "    for tool in tools_to_call:\n",
    "        output = None\n",
    "        tool_call_id = tool.id\n",
    "        function_name = tool.function.name\n",
    "        function_args = tool.function.arguments\n",
    "\n",
    "        if function_name == \"web_search\":\n",
    "            output = web_search_func(q=json.loads(function_args)[\"query\"])\n",
    "\n",
    "        if output:\n",
    "            tool_output_array.append({\"tool_call_id\": tool_call_id, \"output\": output})\n",
    "\n",
    "    return tool_output_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tool_call_id': 'call_FJ8YfNR7IzXlG30zFop0yPGZ', 'output': \"there isn't much new developments on the program.\"}]\n"
     ]
    }
   ],
   "source": [
    "tool_res = submit_tool_outputs(tools_to_call)\n",
    "print(tool_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.submit_tool_outputs(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id,\n",
    "    tool_outputs=tool_res\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: completed\n"
     ]
    }
   ],
   "source": [
    "run = wait_for_run_completion(thread.id,run.id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- see the messages, looks like search results are incoporated in answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: It appears that there are no significant new developments on IMF programs as of the latest information available up to April 2023. The IMF often has several ongoing programs with member countries, and the status or updates of these can vary significantly based on the country and the specific circumstances of the program. If there is a particular country or program you are interested in, please provide more details so that I can search for the most recent developments related to that specific case.\n",
      "=============\n",
      "user: what is the most recent developments on the program?\n",
      "=============\n",
      "assistant: The most recent general developments on the International Monetary Fund (IMF) programs include the IMF's continued effort to provide financial support to countries affected by economic crises, giving them breathing space to implement policies aimed at restoring economic stability and growth. Additionally, the IMF provides precautionary financing to help prevent crises. IMF lending practices are consistently revised to cater to the changing needs of member countries.\n",
      "\n",
      "For more specific information about the latest developments with a particular IMF program or decision, I would need further details such as the name of the country or the specific program you are inquiring about. If you have a specific case or country in mind, please let me know so I can look for the latest details concerning that particular program.\n",
      "=============\n",
      "user: what is the most recent developments on the program?\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "## retrieve the message \n",
    "return_messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "for each in return_messages:\n",
    "  print(each.role+\": {}\".format(each.content[0].text.value))\n",
    "  print(\"=============\")\n",
    "##print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
