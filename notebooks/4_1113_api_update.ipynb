{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI 1113 api update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0,'../libs')\n",
    "from utils import load_json,logging,exception_handler\n",
    "from llm_utils import get_oai_fees\n",
    "## load API Key\n",
    "key = load_json('/home/chengyu.huang/project/Fund_projects/openai_key.json') \n",
    "os.environ['OPENAI_API_KEY'] = key['ChatGPT2']['API_KEY']\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a base openai agent class \n",
    "class BSAgent():\n",
    "    def __init__(self, api_key=None, \n",
    "                 model=\"gpt-3.5-turbo-1106\", \n",
    "                 temperature=0):\n",
    "\n",
    "        if not api_key:\n",
    "            api_key = os.environ['OPENAI_API_KEY']\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.temperature = temperature\n",
    "        if model:\n",
    "            self.model = model\n",
    "        self.message = []\n",
    "\n",
    "    def _add_messages_history(self, response) -> None:\n",
    "\n",
    "        self.message.append(response[\"choices\"][0][\"message\"])\n",
    "\n",
    "    @exception_handler(error_msg='Failed with multiple retry',\n",
    "                        error_return=None,\n",
    "                        attempts=3,delay=5)\n",
    "    def get_completion(self,\n",
    "                       prompt_template, \n",
    "                       model=None,\n",
    "                       temperature=None,\n",
    "                       conv_history=[],\n",
    "                       return_cost=False,\n",
    "                       verbose=True,\n",
    "                       stream=False):\n",
    "        if not model:\n",
    "            model = self.model\n",
    "        \n",
    "        if not temperature:\n",
    "            temperature = self.temperature\n",
    "        \n",
    "        new_message = []\n",
    "        if prompt_template.get('System'):\n",
    "            new_message.append({\"role\": \"system\", \"content\": prompt_template['System']})\n",
    "        if prompt_template.get('Human'):\n",
    "            new_message.append({\"role\": \"user\", \"content\": prompt_template['Human']})\n",
    "        \n",
    "        conv_history.extend(new_message)\n",
    "        \n",
    "        if len(conv_history) == 0 :\n",
    "            raise Exception('prompt template error, prompt must be a dict with with System message or Human message.')\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=conv_history,\n",
    "                    temperature=temperature,\n",
    "                    stream=stream\n",
    "                )\n",
    "        \n",
    "        if not stream:\n",
    "            prompt_tokens = response.usage.prompt_tokens\n",
    "            completion_tokens = response.usage.completion_tokens\n",
    "            this_time_price = get_oai_fees(model, prompt_tokens, completion_tokens)\n",
    "            if verbose:\n",
    "                logging.info(f\"************|||----|||price: {this_time_price}|||----|||************\")\n",
    "        \n",
    "        if return_cost:\n",
    "            return response,this_time_price\n",
    "        \n",
    "        return response \n",
    "    \n",
    "    def get_response_content(self,**kwargs):\n",
    "        response = self.get_completion(**kwargs)\n",
    "        res_msg = response.choices[0].message.content\n",
    "        return res_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate an llm agent\n",
    "llm_agent = BSAgent(model=\"gpt-3.5-turbo-1106\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a language model AI created by OpenAI, and I don't have a personal name. You can just call me \"Assistant.\" How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "pt = {'System':'You are a helpful assistant.',\n",
    "      'Human':'What is your name?'}\n",
    "res = llm_agent.get_response_content(prompt_template=pt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a helpful assistant here to answer your questions and assist you with tasks. You can call me \"Assistant.\"None"
     ]
    }
   ],
   "source": [
    "completion = llm_agent.get_completion(prompt_template=pt,stream=True)\n",
    "for chunk in completion:\n",
    "  print(chunk.choices[0].delta.content,end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch complete\n",
    "- https://platform.openai.com/docs/guides/rate-limits/batching-requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4 vision preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='The image shows a scenic natural landscape featuring a wooden boardwalk extending across a green grassy field. The boardwalk leads towards the horizon and seems to provide a path through the high grass, perhaps in a wetland or marsh area. The sky is partly cloudy with fluffy blue and white clouds, suggesting it is either a late afternoon or a tranquil morning. The greenery and the clear sky contribute to the serenity of the landscape. There are also some shrubs or bushes and a few trees scattered in the distance, accentuating the diverse vegetation of the area. The image exudes a sense of peace and might be used to depict topics related to nature walks, conservation areas, wetlands, or the beauty of untouched landscapes.', role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'stop', 'stop': '<|fim_suffix|>'})\n"
     ]
    }
   ],
   "source": [
    "response = llm_agent.client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Assistnat API Demo\n",
    "- upload file for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-0IovNjuAFjxEXjkIqrQ6Vga6\n"
     ]
    }
   ],
   "source": [
    "## upload a file \n",
    "sample_file = '/home/chengyu.huang/project/Fund_projects/temp_data/174_638_R0.pdf'\n",
    "assert os.path.exists(sample_file)\n",
    "file = client.files.create(\n",
    "    file=open(sample_file,'rb'),\n",
    "    purpose='assistants'\n",
    ")\n",
    "print(file.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[FileObject](data=[FileObject(id='file-0IovNjuAFjxEXjkIqrQ6Vga6', bytes=1726558, created_at=1699990845, filename='174_638_R0.pdf', object='file', purpose='assistants', status='processed', status_details=None)], object='list', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "# list out existing files \n",
    "file_list = client.files.list()\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create the assistant, give it access to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asst_S7tADW8enJ07mcZt11hSOgzx\n"
     ]
    }
   ],
   "source": [
    "# Add the file to the assistant \n",
    "file_id = file_list.data[0].id\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=\"You are a chatbot designed to respond to enquires about the IMF lending program. Use your knowledge base to best respond to user questions\",\n",
    "    model=\"gpt-3.5-turbo-1106\",\n",
    "    tools=[{\"type\":\"retrieval\"}],\n",
    "    file_ids = [file_id]\n",
    ")\n",
    "## you can use client.beta.assistants.update if you need to change some of the settings\n",
    "print(assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can also retrieve an existing assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assistant(id='asst_S7tADW8enJ07mcZt11hSOgzx', created_at=1699990853, description=None, file_ids=['file-0IovNjuAFjxEXjkIqrQ6Vga6'], instructions='You are a chatbot designed to respond to enquires about the IMF lending program. Use your knowledge base to best respond to user questions', metadata={}, model='gpt-3.5-turbo-1106', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])]\n"
     ]
    }
   ],
   "source": [
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\"\n",
    ")\n",
    "print(my_assistants.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_S7tADW8enJ07mcZt11hSOgzx', created_at=1699990853, description=None, file_ids=['file-0IovNjuAFjxEXjkIqrQ6Vga6'], instructions='You are a chatbot designed to respond to enquires about the IMF lending program. Use your knowledge base to best respond to user questions', metadata={}, model='gpt-3.5-turbo-1106', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])\n"
     ]
    }
   ],
   "source": [
    "## retrieive a assistant \n",
    "assistant_id = my_assistants.data[0].id\n",
    "assistant = client.beta.assistants.retrieve(assistant_id)\n",
    "print(assistant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an empty thread and add message to the thread and run the assistant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread(id='thread_eWfRuMQm2RFhMT4DrciYFzO8', created_at=1699990941, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "print(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create message and add to the thread \n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"Can you list the conditionalities required in the imf program\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_SorRFLhD2CGH4e4sfOFBFGBn\n"
     ]
    }
   ],
   "source": [
    "## run the assistant \n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id,\n",
    "    instructions=\"Please address the user as Huang. Do not provide an answer if no usefule infomation was retrieved from konwledge base.\"\n",
    ")\n",
    "\n",
    "print(run.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_progress\n"
     ]
    }
   ],
   "source": [
    "## retrieve the result \n",
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")\n",
    "print(run.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[RunStep](data=[RunStep(id='step_xxYp8F1qsSr5kYwZc8FXX79N', assistant_id='asst_S7tADW8enJ07mcZt11hSOgzx', cancelled_at=None, completed_at=1699990947, created_at=1699990944, expired_at=None, failed_at=None, last_error=None, metadata=None, object='thread.run.step', run_id='run_iX4jsjgKM7arTXqiIOmKw1Tu', status='completed', step_details=MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_jk1C9PXMX7gUl2zXXjgGp3qj'), type='message_creation'), thread_id='thread_eWfRuMQm2RFhMT4DrciYFzO8', type='message_creation', expires_at=None), RunStep(id='step_EwMQMwdvEeutVglYS6O7eyEK', assistant_id='asst_S7tADW8enJ07mcZt11hSOgzx', cancelled_at=None, completed_at=1699990944, created_at=1699990943, expired_at=None, failed_at=None, last_error=None, metadata=None, object='thread.run.step', run_id='run_iX4jsjgKM7arTXqiIOmKw1Tu', status='completed', step_details=ToolCallsStepDetails(tool_calls=[RetrievalToolCall(id='call_OFhhc0AJ2DKPloJ3HRqwVZx3', retrieval={}, type='retrieval')], type='tool_calls'), thread_id='thread_eWfRuMQm2RFhMT4DrciYFzO8', type='tool_calls', expires_at=None)], object='list', first_id='step_xxYp8F1qsSr5kYwZc8FXX79N', last_id='step_EwMQMwdvEeutVglYS6O7eyEK', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "## list out run steps \n",
    "# run_steps = client.beta.threads.runs.steps.list(\n",
    "#     thread_id = thread.id,\n",
    "#     run_id = run.id\n",
    "# )\n",
    "# print(run_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "### how to cancle a run \n",
    "# run = client.beta.threads.runs.cancel(\n",
    "#     thread_id=thread.id,\n",
    "#     run_id = run.id\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: It seems that the specific list of conditionalities is not explicitly stated in the document. If there are any specific terms, policy measures, or requirements related to the IMF program that you would like me to look for, please let me know and I can conduct a search for those specific details.\n",
      "=============\n",
      "assistant: I'm unable to retrieve the specific conditionalities from the document using the quote function. Let me try another approach to locate the details.\n",
      "=============\n",
      "user: Can you list the conditionalities required in the imf program\n",
      "=============\n",
      "assistant: The document provides a summary of the conditionalities related to the request for a Stand-By Arrangement for Greece. Here are the main elements of the program:\n",
      "\n",
      "1. Greece is adopting an ambitious comprehensive multi-year adjustment program to lower the fiscal deficit and the debt ratio, reduce domestic demand in line with capacity, and increase supply and competitiveness.\n",
      "2. The requested Stand-By Arrangement is for €30 billion with an initial purchase of €5.5 billion available upon Board approval, and euro-zone partner countries are prepared to commit €80 billion with a first disbursement of €14.5 billion.\n",
      "3. Fiscal policy is frontloaded with measures of 7½ percent of GDP in 2010, 4 percent of GDP in 2011, and 2 percent of GDP in 2012 and 2013 each to turn around the fiscal position and help place the debt ratio on a downward path.\n",
      "4. The program includes provisions to shield low-income households from the brunt of the adjustment effort, and a Financial Stability Fund will be established to ensure adequate capitalization of the banking system.\n",
      "5. Coordination with the European Commission and the European Central Bank on program implementation and financing will be crucial to the success of the program.\n",
      "6. Risks to the program are high, and Greece needs to persevere to ensure continued international support.\n",
      "\n",
      "This provides an overview of the conditionalities outlined in the document. If you need more specific details or further analysis, please let me know.\n",
      "=============\n",
      "user: Can you sumarize the conditionalities\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "## retrieve the message \n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "for each in messages:\n",
    "  print(each.role+\": {}\".format(each.content[0].text.value))\n",
    "  print(\"=============\")\n",
    "##print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Post test clean up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assistant(id='asst_S7tADW8enJ07mcZt11hSOgzx', created_at=1699990853, description=None, file_ids=['file-0IovNjuAFjxEXjkIqrQ6Vga6'], instructions='You are a chatbot designed to respond to enquires about the IMF lending program. Use your knowledge base to best respond to user questions', metadata={}, model='gpt-3.5-turbo-1106', name=None, object='assistant', tools=[ToolRetrieval(type='retrieval')])]\n"
     ]
    }
   ],
   "source": [
    "my_assistants = client.beta.assistants.list(\n",
    "    order='desc',\n",
    "    limit=\"20\"\n",
    ")\n",
    "print(my_assistants.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssistantDeleted(id='asst_S7tADW8enJ07mcZt11hSOgzx', deleted=True, object='assistant.deleted')\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.assistants.delete('asst_S7tADW8enJ07mcZt11hSOgzx')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
