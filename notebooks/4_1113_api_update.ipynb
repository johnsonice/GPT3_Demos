{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI 1113 api update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.insert(0,'../libs')\n",
    "from utils import load_json,logging,exception_handler\n",
    "from llm_utils import get_oai_fees\n",
    "## load API Key\n",
    "key = load_json('/home/chengyu.huang/project/Fund_projects/openai_key.json') \n",
    "os.environ['OPENAI_API_KEY'] = key['ChatGPT1']['API_KEY']\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a base openai agent class \n",
    "class BSAgent():\n",
    "    def __init__(self, api_key=None, \n",
    "                 model=\"gpt-3.5-turbo-1106\", \n",
    "                 temperature=0):\n",
    "\n",
    "        if not api_key:\n",
    "            api_key = os.environ['OPENAI_API_KEY']\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.temperature = temperature\n",
    "        if model:\n",
    "            self.model = model\n",
    "        self.message = []\n",
    "\n",
    "    def _add_messages_history(self, response) -> None:\n",
    "\n",
    "        self.message.append(response[\"choices\"][0][\"message\"])\n",
    "\n",
    "    @exception_handler(error_msg='Failed with multiple retry',\n",
    "                        error_return=None,\n",
    "                        attempts=3,delay=5)\n",
    "    def get_completion(self,\n",
    "                       prompt_template, \n",
    "                       model=None,\n",
    "                       temperature=None,\n",
    "                       conv_history=[],\n",
    "                       return_cost=False,\n",
    "                       verbose=True,\n",
    "                       stream=False):\n",
    "        if not model:\n",
    "            model = self.model\n",
    "        \n",
    "        if not temperature:\n",
    "            temperature = self.temperature\n",
    "        \n",
    "        new_message = []\n",
    "        if prompt_template.get('System'):\n",
    "            new_message.append({\"role\": \"system\", \"content\": prompt_template['System']})\n",
    "        if prompt_template.get('Human'):\n",
    "            new_message.append({\"role\": \"user\", \"content\": prompt_template['Human']})\n",
    "        \n",
    "        conv_history.extend(new_message)\n",
    "        \n",
    "        if len(conv_history) == 0 :\n",
    "            raise Exception('prompt template error, prompt must be a dict with with System message or Human message.')\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=conv_history,\n",
    "                    temperature=temperature,\n",
    "                    stream=stream\n",
    "                )\n",
    "        \n",
    "        if not stream:\n",
    "            prompt_tokens = response.usage.prompt_tokens\n",
    "            completion_tokens = response.usage.completion_tokens\n",
    "            this_time_price = get_oai_fees(model, prompt_tokens, completion_tokens)\n",
    "            if verbose:\n",
    "                logging.info(f\"************|||----|||price: {this_time_price}|||----|||************\")\n",
    "        \n",
    "        if return_cost:\n",
    "            return response,this_time_price\n",
    "        \n",
    "        return response \n",
    "    \n",
    "    def get_response_content(self,**kwargs):\n",
    "        response = self.get_completion(**kwargs)\n",
    "        res_msg = response.choices[0].message.content\n",
    "        return res_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initiate an llm agent\n",
    "llm_agent = BSAgent(model=\"gpt-3.5-turbo-1106\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a language model AI created by OpenAI, and I don't have a personal name. You can just call me OpenAI Assistant. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "pt = {'System':'You are a helpful assistant.',\n",
    "      'Human':'What is your name?'}\n",
    "res = llm_agent.get_response_content(prompt_template=pt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a helpful assistant here to answer your questions and assist you with tasks. You can call me \"Assistant.\"None"
     ]
    }
   ],
   "source": [
    "completion = llm_agent.get_completion(prompt_template=pt,stream=True)\n",
    "for chunk in completion:\n",
    "  print(chunk.choices[0].delta.content,end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4 vision preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='The image shows a scenic natural landscape featuring a wooden boardwalk extending across a green grassy field. The boardwalk leads towards the horizon and seems to provide a path through the high grass, perhaps in a wetland or marsh area. The sky is partly cloudy with fluffy blue and white clouds, suggesting it is either a late afternoon or a tranquil morning. The greenery and the clear sky contribute to the serenity of the landscape. There are also some shrubs or bushes and a few trees scattered in the distance, accentuating the diverse vegetation of the area. The image exudes a sense of peace and might be used to depict topics related to nature walks, conservation areas, wetlands, or the beauty of untouched landscapes.', role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'stop', 'stop': '<|fim_suffix|>'})\n"
     ]
    }
   ],
   "source": [
    "response = llm_agent.client.chat.completions.create(\n",
    "    model=\"gpt-4-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"Whatâ€™s in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    max_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
