{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db99709f-4aea-4632-b552-0e41e3dac92f",
   "metadata": {},
   "source": [
    "## GPT3 Baisc Demo\n",
    "- follow official documentaion https://beta.openai.com/docs/quickstart\n",
    "- API reference https://beta.openai.com/docs/api-reference/introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b34270bc-1f55-4792-9113-7af739c340fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from utils import load_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42951225-a4b2-4ba6-9847-830eb162f44e",
   "metadata": {},
   "source": [
    "#### Load KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96922ed9-e5e2-40eb-8958-6849061cf500",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_path = '../GPT_SECRET_KEY.json'\n",
    "openai.api_key = load_json(key_path)['API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7732b1f-4361-4aa1-b328-fadfc50d720c",
   "metadata": {},
   "source": [
    "#### Most basic usage - as completation task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9194b49-8382-45e6-83c7-e94c3493de62",
   "metadata": {},
   "source": [
    "#### Function for construction prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47b945be-03b8-4522-8686-187aa794636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def example(inp,out,inp_key=None,out_key=None):\n",
    "    if inp_key and out_key:\n",
    "        return f\"{inp_key}: {inp}\\n{out_key}: {out}\\n\"\n",
    "    else:\n",
    "        return f\"input: {inp}\\noutput: {out}\\n\"\n",
    "\n",
    "def generate_prompt(task_description,examples):\n",
    "    exmp_ins = [example(*e) for e in examples]\n",
    "    task = '{}\\n\\n'.format(task_description)\n",
    "    exmps = '\\n'.join(exmp_ins) + '\\n'\n",
    "    #q = f\"{inp_key}: {query}\\n{out_key}:\"\n",
    "    \n",
    "    return '{}{}'.format(task,exmps)\n",
    "\n",
    "def construct_query(q,inp_key,out_key):\n",
    "    \n",
    "    q = f\"{inp_key}: {query}\\n{out_key}:\"\n",
    "    \n",
    "    return q \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d8b8a1e-ad68-46c8-9fcb-2b62c9d1b0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decide whether a Tweet's sentiment is Positive, Neutral, or Negative.\n",
      "\n",
      "Tweet: I am very happy\n",
      "Sentiment: Positive\n",
      "\n",
      "Tweet: I am not very happy\n",
      "Sentiment: Positive\n",
      "\n",
      "Tweet: I am perfectly fine with that\n",
      "Sentiment: Negative\n",
      "\n",
      "Tweet: I really don't konw\n",
      "Sentiment: Neutral\n",
      "\n",
      "Tweet: I am really excited about this\n",
      "Sentiment:\n"
     ]
    }
   ],
   "source": [
    "### Inputs for prompt \n",
    "task = \"Decide whether a Tweet's sentiment is Positive, Neutral, or Negative.\"\n",
    "example_ins =[('I am very happy','Positive','Tweet','Sentiment'),\n",
    "              ('I am not very happy','Positive','Tweet','Sentiment'),\n",
    "              ('I am perfectly fine with that','Negative','Tweet','Sentiment'),\n",
    "              (\"I really don't konw\",'Neutral','Tweet','Sentiment'),\n",
    "             ] \n",
    "query = \"I am really excited about this\"\n",
    "prompt = generate_prompt(task,example_ins) + construct_query(q=query,inp_key='Tweet',out_key='Sentiment')\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02fbaeed-2abe-4b99-afac-8999e7e43d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"text\": \" Positive\"\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1646422515,\n",
      "  \"id\": \"cmpl-4i7znMPG7o4Km9BMLS333v4O5bHB3\",\n",
      "  \"model\": \"text-davinci:001\",\n",
      "  \"object\": \"text_completion\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-001\",\n",
    "  prompt=prompt,\n",
    "  temperature=0.6\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa84cba-7f15-482b-8285-544586a5ef0d",
   "metadata": {},
   "source": [
    "### Another Example  - multiple responses in one request "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a85e99c-acc3-4605-845a-39c3cdd1e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'Classify the sentiment in these tweets:'\n",
    "task = '{}\\n'.format(task)\n",
    "q = \"\"\"1. \"I can't stand homework\"\n",
    "2. \"This sucks. I'm bored ðŸ˜ \"\n",
    "3. \"I can't wait for Halloween!!!\"\n",
    "4. \"My cat is adorable\"\n",
    "5. \"I hate chocolate\" \n",
    "Tweet sentiment ratings:\"\"\"\n",
    "prompt = task + q \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2ac9f53-e789-4a0c-9ab2-edcdf5394497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the sentiment in these tweets:\n",
      "1. \"I can't stand homework\"\n",
      "2. \"This sucks. I'm bored ðŸ˜ \"\n",
      "3. \"I can't wait for Halloween!!!\"\n",
      "4. \"My cat is adorable\"\n",
      "5. \"I hate chocolate\" \n",
      "Tweet sentiment ratings:\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ba6b317f-14f1-4c9b-b55f-33616353a1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Negative\n",
      "2. Negative\n",
      "3. Positive\n",
      "4. Positive\n",
      "5. Negative\n"
     ]
    }
   ],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"text-davinci-001\",\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=50\n",
    ")\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0119662-d01e-473a-904c-eff5502a9df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt3",
   "language": "python",
   "name": "gpt3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
